{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/15_gcn/04_action_recognition_STA-GCN.ipynb","timestamp":1686786871548}],"gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"WXtcWU-4xWUZ"},"source":["#**Spatial Temporal Attention Graph Convolutional Networks (STA-GCN)**\n"]},{"cell_type":"markdown","metadata":{"id":"OJk-TZgB1M1Z"},"source":["# **BAŞLANGIÇ AYARLAMALARI**\n"]},{"cell_type":"markdown","source":["###**Colab için Drive Bağlantısı**"],"metadata":{"id":"90ZShEOm2iWE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2lQhIa4VqYP"},"outputs":[],"source":["%cd ..\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","!ln -s /content/gdrive/My\\ Drive/ /mydrive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9EerXxnJV5oP"},"outputs":[],"source":["cd /mydrive/Doktora/UYGULAMALAR/STA-GCN/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O2TlwnYXWa_u"},"outputs":[],"source":["ls"]},{"cell_type":"markdown","metadata":{"id":"9soZ6ZzZb5SU"},"source":["###**Gerekli Kütüphaneler ve Tanımlamalar**"]},{"cell_type":"code","metadata":{"id":"D7fRCNHbsZd_"},"source":["import numpy as np\n","import IPython\n","from IPython import display\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageDraw\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Use CUDA:', torch.cuda.is_available())"],"metadata":{"id":"_iH5JYdG-syi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686999588950,"user_tz":-180,"elapsed":243,"user":{"displayName":"Uğur Kılıç","userId":"08537148774711564123"}},"outputId":"a1d57300-8f9b-46ad-a828-34eb3151f422"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Use CUDA: True\n"]}]},{"cell_type":"code","source":["seed = 123\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.use_deterministic_algorithms = True"],"metadata":{"id":"gyimHL_m-uev","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686999590368,"user_tz":-180,"elapsed":4,"user":{"displayName":"Uğur Kılıç","userId":"08537148774711564123"}},"outputId":"121f02c4-6fa7-4fcd-824f-b76ad155284d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f41c87628b0>"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["###**Veri Kümesini Yükleme**"],"metadata":{"id":"XHP0jM2yiNOe"}},{"cell_type":"code","metadata":{"id":"ZMc-yxLl1he6"},"source":["#Yapı: Her veri 80 çerçeve için 25 eklem 3B koordinat içerir.\n","class Feeder(torch.utils.data.Dataset):\n","  def __init__(self, data_path, label_path):\n","      super().__init__()\n","      self.label = np.load(label_path)\n","      self.data = np.load(data_path)\n","\n","  def __len__(self):\n","      return len(self.label)\n","\n","  def __iter__(self):\n","      return self\n","\n","  def __getitem__(self, index):\n","      data = np.array(self.data[index])\n","      label = self.label[index]\n","\n","      return data, label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Komşuluk Matrisi Oluşturma**"],"metadata":{"id":"UaJuJPrTiStX"}},{"cell_type":"code","metadata":{"id":"iPPW553k1m4f"},"source":["#Elimizde sadece koordinat verisi var (düğüm özellikleri). Bağlantılar tanımlanır ve graf çizlir. Bağlantıları ifade etmek için bir komşuluk matrisi kullanılır.\n","class Graph():\n","\n","  def __init__(self, hop_size):\n","    self.get_edge()\n","    self.hop_size = hop_size\n","    self.hop_dis = self.get_hop_distance(self.num_node, self.edge, hop_size=hop_size)\n","    self.get_adjacency()\n","\n","  def __str__(self):\n","    return self.A #yazdırmak isteniyorsa return str(self.A) olmalıdır.\n","\n","  def get_edge(self):\n","    self.num_node = 25\n","    self_link = [(i, i) for i in range(self.num_node)] # frameler arası\n","    neighbor_base = [(1, 2), (2, 21), (3, 21), (4, 3), (5, 21), #aynı frame 24 baglantı\n","                      (6, 5), (7, 6), (8, 7), (9, 21), (10, 9),\n","                      (11, 10), (12, 11), (13, 1), (14, 13), (15, 14),\n","                      (16, 15), (17, 1), (18, 17), (19, 18), (20, 19),\n","                      (22, 23), (23, 8), (24, 25), (25, 12)]\n","    neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_base] #Bu satırda, neighbor_base listesindeki tüm tuple'lardan 1 çıkarılır. Bunun nedeni, Python'da dizinlemenin 0'dan başlamasıdır. Yani, (1, 2) 0 indeksli olarak (0, 1) haline gelir.\n","    self.edge = self_link + neighbor_link\n","#self_link : [(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8), (9, 9), (10, 10), (11, 11), (12, 12), (13, 13), (14, 14), (15, 15), (16, 16), (17, 17), (18, 18), (19, 19), (20, 20), (21, 21), (22, 22), (23, 23), (24, 24)]\n","#neighbor_link: [(1, 2), (2, 21), (3, 21), (4, 3), (5, 21), (6, 5), (7, 6), (8, 7), (9, 21), (10, 9), (11, 10), (12, 11), (13, 1), (14, 13), (15, 14), (16, 15), (17, 1), (18, 17), (19, 18), (20, 19), (22, 23), (23, 8), (24, 25), (25, 12)]\n","#edge: [(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8), (9, 9), (10, 10), (11, 11), (12, 12), (13, 13), (14, 14), (15, 15), (16, 16), (17, 17), (18, 18), (19, 19), (20, 20), (21, 21), (22, 22), (23, 23), (24, 24), (0, 1), (1, 20), (2, 20), (3, 2), (4, 20), (5, 4), (6, 5), (7, 6), (8, 20), (9, 8), (10, 9), (11, 10), (12, 0), (13, 12), (14, 13), (15, 14), (16, 0), (17, 16), (18, 17), (19, 18), (21, 22), (22, 7), (23, 24), (24, 11)]\n","\n","\n","#Bu metod, her iki düğüm arasındaki minimum yol uzunluğunu (hop mesafesi) hesaplar ve bu mesafeleri bir matris şeklinde döndürür.\n","  def get_hop_distance(self, num_node, edge, hop_size):\n","    A = np.zeros((num_node, num_node))\n","    for i, j in edge:\n","        A[j, i] = 1\n","        A[i, j] = 1\n","    hop_dis = np.zeros((num_node, num_node)) + np.inf #sonsuz\n","    transfer_mat = [np.linalg.matrix_power(A, d) for d in range(hop_size + 1)]\n","    arrive_mat = (np.stack(transfer_mat) > 0)\n","    for d in range(hop_size, -1, -1):\n","        hop_dis[arrive_mat[d]] = d\n","    return hop_dis\n","\n","  \"\"\"[[ 0.  1. inf inf inf inf inf inf inf inf inf inf  1. inf inf inf  1. inf inf inf inf inf inf inf inf]\n","      [ 1.  0. inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1. inf inf inf inf]\n","      [inf inf  0.  1. inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1. inf inf inf inf]\n","      [inf inf  1.  0. inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n","      [inf inf inf inf  0.  1. inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1. inf inf inf inf]\n","      [inf inf inf inf  1.  0.  1. inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n","      [inf inf inf inf inf  1.  0.  1. inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n","      [inf inf inf inf inf inf  1.  0. inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1. inf inf]\n","      [inf inf inf inf inf inf inf inf  0.  1. inf inf inf inf inf inf inf inf inf inf  1. inf inf inf inf]\n","      [inf inf inf inf inf inf inf inf  1.  0.  1. inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n","      [inf inf inf inf inf inf inf inf inf  1.  0.  1. inf inf inf inf inf inf inf inf inf inf inf inf inf]\n","      [inf inf inf inf inf inf inf inf inf inf  1.  0. inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n","      ...\n","      [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  0.  1.]\n","      [inf inf inf inf inf inf inf inf inf inf inf  1. inf inf inf inf inf inf inf inf inf inf inf  1.  0.]]\"\"\"\n","\n","\n","#Bu metod, grafikteki düğümler arasındaki komşuluk ilişkisini temsil eden bir adjacency matrisi oluşturur. Ayrıca, matrisi normalize eder.\n","  def get_adjacency(self):\n","    valid_hop = range(0, self.hop_size + 1, 1)\n","    adjacency = np.zeros((self.num_node, self.num_node))\n","    for hop in valid_hop:\n","        adjacency[self.hop_dis == hop] = 1\n","    normalize_adjacency = self.normalize_digraph(adjacency)\n","    A = np.zeros((len(valid_hop), self.num_node, self.num_node))\n","    for i, hop in enumerate(valid_hop):\n","        A[i][self.hop_dis == hop] = normalize_adjacency[self.hop_dis == hop]\n","    self.A = A # 1. boyutta kendi kendi olan yerler 1 olur 2. boyutta ise bağlantı olan yerler 1 ama normalize edilmiş hali\n","\n","\n","\n","#Bu metod, yönlendirilmiş bir grafik olan A matrisini normalize eder. Normalleştirme, kenar ağırlıklarının düğüm dereceleriyle ölçeklendirilmesiyle yapılır.\n","  def normalize_digraph(self, A):\n","    Dl = np.sum(A, 0)\n","    num_node = A.shape[0]\n","    Dn = np.zeros((num_node, num_node))\n","    for i in range(num_node):\n","        if Dl[i] > 0:\n","            Dn[i, i] = Dl[i]**(-1)\n","    DAD = np.dot(A, Dn)\n","    return DAD"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fiBLeys32DpV"},"source":["# **STA-GCN UYGULAMASI**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DObgu2x0-GpM"},"source":["* S_GC: Uzaysal grafik konvolüsyonu\n","* S_GC_att_edge: att_edge ve uzaysal grafik ile konvolüsyon, perception branch\n","* STGC_Block: uzaysal grafik çağırma ve zaman grafiği konvolüsyonu için sınıf.\n","* FeatureExtractor: STGC_block'a birden fazla çağrı.\n","* AttentionBranch: STGC_bloklarına birden fazla çağrı. Dikkat düğümü (Attention node) ve Dikkat kenarı (Attention edge) oluşturur.\n","* PerceptionBranch: STGC_bloklarına birden fazla çağrı. STGC_bloklarında S_GC_att_edge'i çağırmak için koşullu dallanma.\n","* STA-GCN: FeatureExtractor, AttentionBranch ve PerceptionBranch'ı çağırır."]},{"cell_type":"markdown","metadata":{"id":"Brj29MeFVRxf"},"source":["### **S_GG: Uzaysal grafik konvolüsyonu**"]},{"cell_type":"code","metadata":{"id":"P-4U_XyB5EnB"},"source":["class S_GC(nn.Module):\n","  def __init__(self, in_channels, out_channels, s_kernel_size):\n","    super(S_GC, self).__init__()\n","    self.s_kernel_size = s_kernel_size\n","    self.conv = nn.Conv2d(in_channels=in_channels,\n","                          out_channels=out_channels * s_kernel_size,\n","                          kernel_size=1)\n","\n","  def forward(self, x, A, att_edge=None):\n","    x = self.conv(x)\n","    n, kc, t, v = x.size()\n","    x = x.view(n, self.s_kernel_size, kc//self.s_kernel_size, t, v)\n","    x = torch.einsum('nkctv,kvw->nctw', (x, A))\n","    return x.contiguous()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qz0eW0n0XUlO"},"source":["### **S_GG_att_edge**\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"PQ78LHf15Leh"},"source":["class S_GC_att_edge(nn.Module):\n","  def __init__(self, in_channels, out_channels, s_kernel_size, num_att_edge):\n","    super(S_GC_att_edge, self).__init__()\n","    self.num_att_edge = num_att_edge\n","    self.s_kernel_size = s_kernel_size + num_att_edge\n","    self.conv = nn.Conv2d(in_channels=in_channels,\n","                           out_channels=out_channels * self.s_kernel_size,\n","                           kernel_size=1)\n","\n","  def forward(self, x, A, att_edge):\n","    x = self.conv(x)\n","    n, kc, t, v = x.size()\n","    x = x.view(n, self.s_kernel_size, kc//self.s_kernel_size, t, v)\n","    x1 = x[:, :self.s_kernel_size-self.num_att_edge, :, :, :]\n","    x2 = x[:, -self.num_att_edge:, :, :, :]\n","    x1 = torch.einsum('nkctv,kvw->nctw', (x1, A))\n","    x2 = torch.einsum('nkctv,nkvw->nctw', (x2, att_edge))\n","    x_sum = x1 + x2\n","\n","    return x_sum"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"54uuP_uobS8t"},"source":["### **STGC_Block**"]},{"cell_type":"code","metadata":{"id":"aFXbskGb5TTp"},"source":["class STGC_Block(nn.Module):\n","  def __init__(self, in_channels, out_channels, stride, s_kernel_size, t_kernel_size, dropout, A_size, num_att_edge=0, use_att_edge=False):\n","    super(STGC_Block, self).__init__()\n","  # Dikkat kenarı olan veya olmayan uzamsal grafik konvolüsyonu\n","    if not use_att_edge:\n","      self.sgc = S_GC(in_channels=in_channels,\n","                       out_channels=out_channels,\n","                       s_kernel_size=s_kernel_size)\n","\n","    else:\n","      self.sgc = S_GC_att_edge(in_channels=in_channels,\n","                                 out_channels=out_channels,\n","                                 s_kernel_size=s_kernel_size,\n","                                 num_att_edge=num_att_edge)\n","\n","\n","\n","   # Öğrenilebilir ağırlık matrisi M Kenarlara ağırlık verir. Hangi kenarların önemli olduğunu öğrenir.\n","    self.M = nn.Parameter(torch.ones(A_size))\n","\n","  # Zaman grafiği konvolüsyonu\n","    self.tgc = nn.Sequential(nn.BatchNorm2d(out_channels),\n","                            nn.ReLU(),\n","                            nn.Conv2d(out_channels,\n","                                      out_channels,\n","                                      (t_kernel_size, 1),\n","                                      (stride, 1),\n","                                      ((t_kernel_size - 1) // 2, 0)),\n","                            nn.BatchNorm2d(out_channels),\n","                            nn.Dropout(dropout),\n","                            nn.ReLU())\n","\n","    # Artık işleme\n","    if(in_channels == out_channels) and (stride == 1):\n","      self.residual = lambda x: x\n","    else:\n","      self.residual = nn.Sequential(nn.Conv2d(in_channels,\n","                                              out_channels,\n","                                              kernel_size=1,\n","                                              stride=(stride, 1)),\n","                                    nn.BatchNorm2d(out_channels))\n","\n","  def forward(self, x, A, att_edge):\n","    x = self.tgc(self.sgc(x, A * self.M, att_edge)) + self.residual(x)\n","    return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MJtQaVRvbZ0B"},"source":["### **Feature extractor**\n","İskelet verileri girdi olarak kullanıldığında, özellikler birden fazla STGC bloğu ile çıkarılır."]},{"cell_type":"code","metadata":{"id":"YxiFtUhr4x5E"},"source":["class FeatureExtractor(nn.Module):\n","  def __init__(self, config, s_kernel_size, t_kernel_size, dropout, A_size):\n","    super(FeatureExtractor, self).__init__()\n","    # Batch Normalization\n","    self.bn = nn.BatchNorm1d(config[0][0] * A_size[2])\n","\n","    # STGC-Block config\n","    kwargs = dict(s_kernel_size=s_kernel_size,\n","                  t_kernel_size=t_kernel_size,\n","                  dropout=dropout,\n","                  A_size=A_size)\n","    self.stgc_block1 = STGC_Block(config[0][0], config[0][1], config[0][2], **kwargs)\n","    self.stgc_block2 = STGC_Block(config[1][0], config[1][1], config[1][2], **kwargs)\n","    self.stgc_block3 = STGC_Block(config[2][0], config[2][1], config[2][2], **kwargs)\n","\n","  def forward(self, x, A):\n","    # Batch Normalization\n","    N, C, T, V = x.size() # batch, channel, frame, node\n","    x = x.permute(0, 3, 1, 2).contiguous().view(N, V * C, T)\n","    x = self.bn(x)\n","    x = x.view(N, V, C, T).permute(0, 2, 3, 1).contiguous()\n","    # STGC Blocks\n","    x = self.stgc_block1(x, A, None)\n","    x = self.stgc_block2(x, A, None)\n","    x = self.stgc_block3(x, A, None)\n","    return x\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EyEWoEqUbhTL"},"source":["### **Attention branch**\n","3 STGC-Blok'un çıkış değerlerine bağlı olarak bir Dikkat kenarı ve bir Dikkat düğümü oluşturulur."]},{"cell_type":"code","metadata":{"id":"jrznxP7y47BZ"},"source":["class AttentionBranch(nn.Module):\n","  def __init__(self, config, num_classes, num_att_edge, s_kernel_size, t_kernel_size, dropout, A_size):\n","    super(AttentionBranch, self).__init__()\n","    # STGC-Block config\n","    kwargs = dict(s_kernel_size=s_kernel_size,\n","                  t_kernel_size=t_kernel_size,\n","                  dropout=dropout,\n","                  A_size=A_size)\n","    self.stgc_block1 = STGC_Block(config[0][0], config[0][1], config[0][2], **kwargs)\n","    self.stgc_block2 = STGC_Block(config[1][0], config[1][1], config[1][2], **kwargs)\n","    self.stgc_block3 = STGC_Block(config[2][0], config[2][1], config[2][2], **kwargs)\n","\n","    # Prediction\n","    self.fc = nn.Conv2d(config[-1][1], num_classes, kernel_size=1, padding=0)\n","\n","    # Attention\n","    self.att_bn = nn.BatchNorm2d(config[-1][1])\n","    self.att_conv = nn.Conv2d(config[-1][1], num_classes, kernel_size=1, padding=0, stride=1, bias=False)\n","\n","    # Attention node\n","    self.att_node_conv = nn.Conv2d(num_classes, 1, kernel_size=1, padding=0, stride=1, bias=False)\n","    self.att_node_bn = nn.BatchNorm2d(1)\n","    self.sigmoid = nn.Sigmoid()\n","\n","    # Attention edge\n","    self.num_att_edge = num_att_edge\n","    self.att_edge_conv = nn.Conv2d(num_classes, num_att_edge * A_size[2], kernel_size=1, padding=0, stride=1, bias=False)\n","    self.att_edge_bn = nn.BatchNorm2d(num_att_edge * A_size[2])\n","    self.tanh = nn.Tanh()\n","    self.relu = nn.ReLU()\n","\n","  def forward(self, x, A):\n","    N, c, T, V = x.size()\n","\n","    # STGC Block\n","    x = self.stgc_block1(x, A, None)\n","    x = self.stgc_block2(x, A, None)\n","    x = self.stgc_block3(x, A, None)\n","\n","    # Prediction\n","    x_out = F.avg_pool2d(x, x.size()[2:])\n","    x_out = x_out.view(N, -1, 1, 1)\n","    x_out = self.fc(x_out)\n","    output = x_out.view(x_out.size(0), -1)\n","\n","    # Attention\n","    x_att = self.att_bn(x)\n","    x_att = self.att_conv(x_att)\n","\n","    # Attention node\n","    x_node = self.att_node_conv(x_att)\n","    x_node = self.att_node_bn(x_node)\n","    x_node = F.interpolate(x_node, size=(T, V))\n","    att_node = self.sigmoid(x_node)\n","\n","    # Attention edge\n","    x_edge = F.avg_pool2d(x_att, (x_att.size()[2], 1))\n","    x_edge = self.att_edge_conv(x_edge)\n","    x_edge = self.att_edge_bn(x_edge)\n","    x_edge = x_edge.view(N, self.num_att_edge, V, V)\n","    x_edge = self.tanh(x_edge)\n","    att_edge = self.relu(x_edge)\n","\n","    return output, att_node, att_edge"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cOBVqZlKbo0p"},"source":["### **Perception branch**\n"]},{"cell_type":"code","metadata":{"id":"s7sixxL747hL"},"source":["class PerceptionBranch(nn.Module):\n","  def __init__(self, config, num_classes, num_att_edge, s_kernel_size, t_kernel_size, dropout, A_size, use_att_edge=True):\n","    super(PerceptionBranch, self).__init__()\n","    # STGC-Block config\n","    kwargs = dict(s_kernel_size=s_kernel_size,\n","                  t_kernel_size=t_kernel_size,\n","                  dropout=dropout,\n","                  A_size=A_size,\n","                  num_att_edge=num_att_edge,\n","                  use_att_edge=use_att_edge)\n","    self.stgc_block1 = STGC_Block(config[0][0], config[0][1], config[0][2], **kwargs)\n","    self.stgc_block2 = STGC_Block(config[1][0], config[1][1], config[1][2], **kwargs)\n","    self.stgc_block3 = STGC_Block(config[2][0], config[2][1], config[2][2], **kwargs)\n","\n","    # Prediction\n","    self.fc = nn.Conv2d(config[-1][1], num_classes, kernel_size=1, padding=0)\n","\n","  def forward(self, x, A, att_edge):\n","    N, c, T, V = x.size()\n","    # STGC Block\n","    x = self.stgc_block1(x, A, att_edge)\n","    x = self.stgc_block2(x, A, att_edge)\n","    x = self.stgc_block3(x, A, att_edge)\n","\n","    # Prediction\n","    x = F.avg_pool2d(x, x.size()[2:])\n","    x = x.view(N, -1, 1, 1)\n","    x = self.fc(x)\n","    output = x.view(x.size(0), -1)\n","\n","    return output\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rn3f2hE7btro"},"source":["### **STA-GCN**"]},{"cell_type":"markdown","metadata":{"id":"qKd-fSlJpx8O"},"source":["Ağı tamamlamak için FeatureExtractor, AttentionBranch ve PercepitonBranch çağrılır"]},{"cell_type":"code","metadata":{"id":"lXiCIzVO3_UA"},"source":["class STA_GCN(nn.Module):\n","  def __init__(self, num_classes, in_channels, t_kernel_size, hop_size, num_att_edge, dropout=0.5):\n","    super(STA_GCN, self).__init__()\n","\n","    # Graph\n","    graph = Graph(hop_size)\n","    A = torch.tensor(graph.A, dtype=torch.float32, requires_grad=False)\n","    self.register_buffer('A', A)\n","\n","    kwargs = dict(s_kernel_size=A.size(0),\n","                   t_kernel_size=t_kernel_size,\n","                   dropout=dropout,\n","                   A_size=A.size())\n","\n","    # Feature extractor\n","    f_config = [[in_channels, 32, 1], [32, 32, 1], [32, 32, 1]]\n","    self.feature_extractor = FeatureExtractor(f_config, **kwargs)\n","\n","    # Attention branch\n","    a_config = [[32, 64, 2], [64, 64, 1], [64, 64, 1]]\n","    self.attention_branch = AttentionBranch(a_config, num_classes, num_att_edge, **kwargs)\n","\n","    # Perception branch\n","    p_config = [[32, 64, 2], [64, 64, 1], [64, 64, 1]]\n","    self.perception_branch = PerceptionBranch(p_config, num_classes, num_att_edge, **kwargs)\n","\n","  def forward(self, x):\n","    # Feature extractor\n","    feature = self.feature_extractor(x, self.A)\n","\n","    # Attention branch\n","    output_ab, att_node, att_edge = self.attention_branch(feature, self.A)\n","\n","    # Attention mechanism\n","    att_x = feature * att_node\n","\n","    # Perception branch\n","    output_pb = self.perception_branch(att_x, self.A, att_edge)\n","\n","    return output_ab, output_pb, att_node, att_edge"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V7td2a2Q2Oo-"},"source":["#**MODEL EĞİTİMİ**\n","\n"]},{"cell_type":"code","source":["NUM_EPOCH = 100\n","BATCH_SIZE = 64\n","HOP_SIZE = 2\n","NUM_ATT_EDGE = 2 #4 her eylem için oluşturulan dikkat kenarı sayısı, işlem basına\n","\n","# Model oluşturun.\n","model = STA_GCN(num_classes=14,\n","                  in_channels=3,\n","                  t_kernel_size=9, # Zaman grafiği konvolüsyonu için çekirdek boyutu (t_kernel_size × 1)\n","                  hop_size=HOP_SIZE,\n","                  num_att_edge=NUM_ATT_EDGE).cuda()\n","\n","torch.save(model.state_dict(), 'model_weights_normal_50.pth')\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","# Hata fonksiyonu.\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","\n","\n","data_loader = dict()\n","data_loader['train'] = torch.utils.data.DataLoader(dataset=Feeder(data_path='../DATASETS/cs_data/train_data.npy', label_path='../DATASETS/cs_data/train_label.npy'), batch_size=BATCH_SIZE, shuffle=True,)\n","data_loader['test'] = torch.utils.data.DataLoader(dataset=Feeder(data_path='../DATASETS/cs_data/test_data.npy', label_path='../DATASETS/cs_data/test_label.npy'), batch_size=BATCH_SIZE, shuffle=False)\n","\n","\n","#model.train()\n","\n","# Öğrenmeye başla\n","for epoch in range(50, NUM_EPOCH+1):\n","  correct_pb = 0\n","  sum_loss = 0\n","  for batch_idx, (data, label) in enumerate(data_loader['train']):\n","    data = data.cuda()\n","    label = label.cuda()\n","\n","    output_ab, output_pb, _, _ = model(data)\n","\n","    loss = criterion(output_ab, label) + criterion(output_pb, label)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    sum_loss += loss.item()\n","    _, predict = torch.max(output_pb.data, 1)\n","    correct_pb += (predict == label).sum().item()\n","\n","  print('# Epoch: {} | Loss: {:.4f} | Accuracy PB: {:.3f}[%]'.format(epoch, sum_loss/len(data_loader['train']), (100. * correct_pb / len(data_loader['train'].dataset))))\n","  torch.save(model.state_dict(), 'model_weights_normal_100.pth')"],"metadata":{"id":"xo3e3XvU-33P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687002655490,"user_tz":-180,"elapsed":1431520,"user":{"displayName":"Uğur Kılıç","userId":"08537148774711564123"}},"outputId":"c6e44e95-897e-4515-aeb1-bef85c05109a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["# Epoch: 50 | Loss: 4.7477 | Accuracy PB: 18.503[%]\n","# Epoch: 51 | Loss: 3.9162 | Accuracy PB: 34.206[%]\n","# Epoch: 52 | Loss: 3.5053 | Accuracy PB: 42.320[%]\n","# Epoch: 53 | Loss: 2.9922 | Accuracy PB: 50.583[%]\n","# Epoch: 54 | Loss: 2.5255 | Accuracy PB: 57.851[%]\n","# Epoch: 55 | Loss: 2.2302 | Accuracy PB: 62.929[%]\n","# Epoch: 56 | Loss: 2.0154 | Accuracy PB: 67.354[%]\n","# Epoch: 57 | Loss: 1.8495 | Accuracy PB: 70.551[%]\n","# Epoch: 58 | Loss: 1.7373 | Accuracy PB: 72.838[%]\n","# Epoch: 59 | Loss: 1.6681 | Accuracy PB: 74.527[%]\n","# Epoch: 60 | Loss: 1.5865 | Accuracy PB: 75.297[%]\n","# Epoch: 61 | Loss: 1.4898 | Accuracy PB: 77.509[%]\n","# Epoch: 62 | Loss: 1.4110 | Accuracy PB: 78.963[%]\n","# Epoch: 63 | Loss: 1.3861 | Accuracy PB: 79.647[%]\n","# Epoch: 64 | Loss: 1.3141 | Accuracy PB: 80.513[%]\n","# Epoch: 65 | Loss: 1.2464 | Accuracy PB: 81.229[%]\n","# Epoch: 66 | Loss: 1.2342 | Accuracy PB: 81.903[%]\n","# Epoch: 67 | Loss: 1.1879 | Accuracy PB: 82.170[%]\n","# Epoch: 68 | Loss: 1.1265 | Accuracy PB: 83.218[%]\n","# Epoch: 69 | Loss: 1.1001 | Accuracy PB: 83.699[%]\n","# Epoch: 70 | Loss: 1.0745 | Accuracy PB: 84.051[%]\n","# Epoch: 71 | Loss: 1.0344 | Accuracy PB: 85.120[%]\n","# Epoch: 72 | Loss: 0.9858 | Accuracy PB: 85.366[%]\n","# Epoch: 73 | Loss: 1.0009 | Accuracy PB: 85.452[%]\n","# Epoch: 74 | Loss: 1.0352 | Accuracy PB: 84.393[%]\n","# Epoch: 75 | Loss: 0.9386 | Accuracy PB: 86.093[%]\n","# Epoch: 76 | Loss: 0.8998 | Accuracy PB: 86.916[%]\n","# Epoch: 77 | Loss: 0.9063 | Accuracy PB: 86.873[%]\n","# Epoch: 78 | Loss: 0.8850 | Accuracy PB: 86.638[%]\n","# Epoch: 79 | Loss: 0.8815 | Accuracy PB: 86.980[%]\n","# Epoch: 80 | Loss: 0.8549 | Accuracy PB: 87.215[%]\n","# Epoch: 81 | Loss: 0.8219 | Accuracy PB: 87.932[%]\n","# Epoch: 82 | Loss: 0.8274 | Accuracy PB: 87.611[%]\n","# Epoch: 83 | Loss: 0.7812 | Accuracy PB: 88.306[%]\n","# Epoch: 84 | Loss: 0.7838 | Accuracy PB: 88.445[%]\n","# Epoch: 85 | Loss: 0.7684 | Accuracy PB: 88.445[%]\n","# Epoch: 86 | Loss: 0.7476 | Accuracy PB: 89.129[%]\n","# Epoch: 87 | Loss: 0.7237 | Accuracy PB: 89.503[%]\n","# Epoch: 88 | Loss: 0.7268 | Accuracy PB: 89.364[%]\n","# Epoch: 89 | Loss: 0.7283 | Accuracy PB: 89.182[%]\n","# Epoch: 90 | Loss: 0.7181 | Accuracy PB: 89.621[%]\n","# Epoch: 91 | Loss: 0.6820 | Accuracy PB: 90.198[%]\n","# Epoch: 92 | Loss: 0.6782 | Accuracy PB: 90.005[%]\n","# Epoch: 93 | Loss: 0.6517 | Accuracy PB: 90.700[%]\n","# Epoch: 94 | Loss: 0.6562 | Accuracy PB: 90.775[%]\n","# Epoch: 95 | Loss: 0.6536 | Accuracy PB: 90.615[%]\n","# Epoch: 96 | Loss: 0.6195 | Accuracy PB: 91.021[%]\n","# Epoch: 97 | Loss: 0.6061 | Accuracy PB: 91.213[%]\n","# Epoch: 98 | Loss: 0.6046 | Accuracy PB: 91.395[%]\n","# Epoch: 99 | Loss: 0.6115 | Accuracy PB: 91.096[%]\n","# Epoch: 100 | Loss: 0.5861 | Accuracy PB: 91.748[%]\n"]}]},{"cell_type":"code","source":["data_loader = dict()\n","BATCH_SIZE = 64\n","data_loader['test'] = torch.utils.data.DataLoader(dataset=Feeder(data_path='../DATASETS/cs_data/test_data.npy', label_path='../DATASETS/cs_data/test_label.npy'), batch_size=BATCH_SIZE, shuffle=False)\n","# model oluştur\n","NUM_EPOCH = 200\n","\n","HOP_SIZE = 2\n","NUM_ATT_EDGE = 2 # her eylem için oluşturulan dikkat kenarı sayısı, işlem basına\n","\n","# Model oluşturun.\n","model = STA_GCN(num_classes=14,\n","                  in_channels=3,\n","                  t_kernel_size=9, # Zaman grafiği konvolüsyonu için çekirdek boyutu (t_kernel_size × 1)\n","                  hop_size=HOP_SIZE,\n","                  num_att_edge=NUM_ATT_EDGE).cuda()\n","# Model yapısnı oluştur\n","\n","\n","\n","# Kaydedilmiş ağırlıkları yükle\n","model.load_state_dict(torch.load('model_weights_2.pth'))\n","sum(p.numel() for p in model.parameters() if p.requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9IK_VvB14io6","executionInfo":{"status":"ok","timestamp":1686931291617,"user_tz":-180,"elapsed":8620,"user":{"displayName":"Uğur Kılıç","userId":"08537148774711564123"}},"outputId":"8f5f3c47-fc35-4342-f1e9-d950a5dfcc49"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":16},{"output_type":"execute_result","data":{"text/plain":["366765"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"_SkbuXlB27lW"},"source":["#**MODEL DEĞERLENDİRMESİ**\n"]},{"cell_type":"code","source":["#Modeli değerlendirme moduna değiştir\n","\n","data_loader = dict()\n","BATCH_SIZE = 64\n","HOP_SIZE = 2\n","NUM_ATT_EDGE = 2\n","data_loader['test'] = torch.utils.data.DataLoader(dataset=Feeder(data_path='../DATASETS/cs_data/test_data.npy', label_path='../DATASETS/cs_data/test_label.npy'), batch_size=BATCH_SIZE, shuffle=False)\n","\n","# Model oluşturun.\n","model = STA_GCN(num_classes=14,\n","                  in_channels=3,\n","                  t_kernel_size=9, # Zaman grafiği konvolüsyonu için çekirdek boyutu (t_kernel_size × 1)\n","                  hop_size=HOP_SIZE,\n","                  num_att_edge=NUM_ATT_EDGE)\n","\n","# Kaydedilmiş ağırlıkları yükle\n","#model.load_state_dict(torch.load('model_weights_100.pth'))\n","model.load_state_dict(torch.load('model_weights_100.pth', map_location=torch.device('cpu')))\n","# modeli değerlendirme moduna değiştir\n","model.eval()\n","\n","correct_pb = 0\n","confusion_matrix = np.zeros((14, 14))\n","with torch.no_grad():\n","  for batch_idx, (data, label) in enumerate(data_loader['test']):\n","#    data = data.cuda()\n","#    label = label.cuda()\n","\n","    output_ab, output_pb, _, _ = model(data)\n","\n","    _, predict = torch.max(output_pb.data, 1)\n","    correct_pb += (predict == label).sum().item()\n","\n","    for l, p in zip(label.view(-1), predict.view(-1)):\n","      confusion_matrix[l.long(), p.long()] += 1\n","\n","len_cm = len(confusion_matrix)\n","for i in range(len_cm):\n","    sum_cm = np.sum(confusion_matrix[i])\n","    for j in range(len_cm):\n","        confusion_matrix[i][j] = 100 * (confusion_matrix[i][j] / sum_cm)\n","\n","classes = ['pick up','sit down','stand up','put on jacket',\n","           'take off jacket','put on a shoe','put on glasses','take off glasses',\n","           'put on a hat/cap','take off a hat/cap','cheer up','hand waving',\n","           'hopping', 'jump up']\n","\n","plt.imshow(confusion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n","plt.title('Confusion matrix')\n","plt.tight_layout()\n","tick_marks = np.arange(len(classes))\n","plt.xticks(tick_marks, classes, rotation=90)\n","plt.yticks(tick_marks, classes)\n","plt.ylabel('True')\n","plt.xlabel('Predicted')\n","plt.show()\n","\n","print('# Test Accuracy PB: {:.3f}[%]'.format((100. * correct_pb / len(data_loader['test'].dataset))))"],"metadata":{"id":"cl952xX5-5_0"},"execution_count":null,"outputs":[]}]}